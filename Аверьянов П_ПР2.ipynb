{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Практическая работа 2. Обнаружение атак на веб-приложения с применением\n",
        "обучения с подкреплением\n",
        "\n",
        "Цель работы: Освоить методы обнаружения и предотвращения атак на\n",
        "веб-приложения (SQL-инъекции, XSS, DDoS) с использованием обучения с\n",
        "подкреплением (Reinforcement Learning, RL).\n"
      ],
      "metadata": {
        "id": "FCADiZ8fI4I1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание:\n",
        "\n",
        "Изучить основные типы атак на веб-приложения: SQL-инъекции, XSS, DDoS.\n",
        "Подготовить датасет с примерами нормального и аномального трафика. Разработать\n",
        "среду RL на основе OpenAI Gym для моделирования веб-трафика.Реализовать агента\n",
        "обучения с подкреплением для автоматической фильтрации атакующего трафика.\n",
        "Провести обучение агента и оценить его эффективность."
      ],
      "metadata": {
        "id": "kZ-Zy3L6JJ-4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "4T31lJnTwnNc",
        "outputId": "6fc2a30a-2f81-4cdb-ed41-36262b0b29a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   packet_rate  inter_arrival_time  packet_size  duration  src_port  dst_port  \\\n",
              "0    32.052620            0.622677   419.336437  4.460177      8801      9250   \n",
              "1    52.933578            0.492452   846.565643  4.435679      3708     51281   \n",
              "2    96.720151            0.185046   502.168275  4.431496     15306      6832   \n",
              "3    80.637373            0.137000   462.529046  4.675813     48304      9779   \n",
              "4    29.855090            0.601742   785.058163  5.295717     32704     65071   \n",
              "\n",
              "   num_packets    num_bytes protocol           src_ip          dst_ip   label  \n",
              "0    73.206250  7068.070150     ICMP   53.110.216.129    177.21.88.93  attack  \n",
              "1    38.226238  3848.110143      TCP    218.27.101.33  188.53.205.189  normal  \n",
              "2    32.990155  7600.730151      TCP     70.115.47.70   115.8.160.190  attack  \n",
              "3    71.610137  9700.654230     ICMP   173.214.29.104  112.116.204.53  attack  \n",
              "4    43.491605  4619.087460      TCP  120.227.151.189    201.71.89.46  normal  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7aca4d44-5a80-4f3a-99ac-147538f67f97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>packet_rate</th>\n",
              "      <th>inter_arrival_time</th>\n",
              "      <th>packet_size</th>\n",
              "      <th>duration</th>\n",
              "      <th>src_port</th>\n",
              "      <th>dst_port</th>\n",
              "      <th>num_packets</th>\n",
              "      <th>num_bytes</th>\n",
              "      <th>protocol</th>\n",
              "      <th>src_ip</th>\n",
              "      <th>dst_ip</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32.052620</td>\n",
              "      <td>0.622677</td>\n",
              "      <td>419.336437</td>\n",
              "      <td>4.460177</td>\n",
              "      <td>8801</td>\n",
              "      <td>9250</td>\n",
              "      <td>73.206250</td>\n",
              "      <td>7068.070150</td>\n",
              "      <td>ICMP</td>\n",
              "      <td>53.110.216.129</td>\n",
              "      <td>177.21.88.93</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>52.933578</td>\n",
              "      <td>0.492452</td>\n",
              "      <td>846.565643</td>\n",
              "      <td>4.435679</td>\n",
              "      <td>3708</td>\n",
              "      <td>51281</td>\n",
              "      <td>38.226238</td>\n",
              "      <td>3848.110143</td>\n",
              "      <td>TCP</td>\n",
              "      <td>218.27.101.33</td>\n",
              "      <td>188.53.205.189</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>96.720151</td>\n",
              "      <td>0.185046</td>\n",
              "      <td>502.168275</td>\n",
              "      <td>4.431496</td>\n",
              "      <td>15306</td>\n",
              "      <td>6832</td>\n",
              "      <td>32.990155</td>\n",
              "      <td>7600.730151</td>\n",
              "      <td>TCP</td>\n",
              "      <td>70.115.47.70</td>\n",
              "      <td>115.8.160.190</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80.637373</td>\n",
              "      <td>0.137000</td>\n",
              "      <td>462.529046</td>\n",
              "      <td>4.675813</td>\n",
              "      <td>48304</td>\n",
              "      <td>9779</td>\n",
              "      <td>71.610137</td>\n",
              "      <td>9700.654230</td>\n",
              "      <td>ICMP</td>\n",
              "      <td>173.214.29.104</td>\n",
              "      <td>112.116.204.53</td>\n",
              "      <td>attack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>29.855090</td>\n",
              "      <td>0.601742</td>\n",
              "      <td>785.058163</td>\n",
              "      <td>5.295717</td>\n",
              "      <td>32704</td>\n",
              "      <td>65071</td>\n",
              "      <td>43.491605</td>\n",
              "      <td>4619.087460</td>\n",
              "      <td>TCP</td>\n",
              "      <td>120.227.151.189</td>\n",
              "      <td>201.71.89.46</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7aca4d44-5a80-4f3a-99ac-147538f67f97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7aca4d44-5a80-4f3a-99ac-147538f67f97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7aca4d44-5a80-4f3a-99ac-147538f67f97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-135c507b-c33d-4ecc-b3d0-3274f2d9508b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-135c507b-c33d-4ecc-b3d0-3274f2d9508b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-135c507b-c33d-4ecc-b3d0-3274f2d9508b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1999,\n  \"fields\": [\n    {\n      \"column\": \"packet_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27.333560457498532,\n        \"min\": 6.765443390496717,\n        \"max\": 160.52275989545686,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          96.36625110097928,\n          60.20327287368049,\n          60.18047321455949\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inter_arrival_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18098553805107634,\n        \"min\": 0.0767889765173756,\n        \"max\": 1.0879589253790858,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          0.2035972783891874,\n          0.3314954553955721,\n          0.6376752328897206\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"packet_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 269.8837026181031,\n        \"min\": 303.22572917849163,\n        \"max\": 1327.7915796893217,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          545.647104498695,\n          623.986402253252,\n          949.6794734775676\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0101168168588617,\n        \"min\": 1.6701232169570654,\n        \"max\": 8.353725325206408,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          4.59655465700998,\n          5.043990221016313,\n          3.20101133906338\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"src_port\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18704,\n        \"min\": 1049,\n        \"max\": 65532,\n        \"num_unique_values\": 1969,\n        \"samples\": [\n          9253,\n          59658,\n          42014\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dst_port\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18728,\n        \"min\": 1065,\n        \"max\": 65497,\n        \"num_unique_values\": 1965,\n        \"samples\": [\n          30354,\n          12746,\n          37267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_packets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.061267688345957,\n        \"min\": 17.707249476179612,\n        \"max\": 132.7880919017134,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          80.60790361903932,\n          46.8795991399649,\n          39.09672288340946\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_bytes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1389.7644875178148,\n        \"min\": 1018.1091266821776,\n        \"max\": 11172.015786662228,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          4099.066057725138,\n          8313.530660815048,\n          5981.13568574663\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protocol\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ICMP\",\n          \"TCP\",\n          \"UDP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"src_ip\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          \"149.186.75.99\",\n          \"27.182.50.136\",\n          \"98.157.174.65\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dst_ip\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          \"185.70.174.35\",\n          \"49.218.106.60\",\n          \"174.242.102.95\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"normal\",\n          \"attack\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd  # Импортируем библиотеку pandas для работы с данными\n",
        "from sklearn.model_selection import train_test_split  # Импортируем функцию для разделения данных на обучающую и тестовую выборки\n",
        "from sklearn.preprocessing import StandardScaler  # Импортируем стандартный скейлер для нормализации данных\n",
        "\n",
        "# Загрузим датасет из CSV файла\n",
        "data = pd.read_csv('/content/ddos.csv')  # Читаем данные из файла 'ddos.csv' и сохраняем в переменной data\n",
        "data.head()  # Выводим первые 5 строк датасета для предварительного просмотра\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предварительно обрабатываем данные, преобразуя их в формат, пригодный для обучения."
      ],
      "metadata": {
        "id": "nO3AjRAMK7dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder  # Импортируем MinMaxScaler для нормализации данных и LabelEncoder для кодирования меток\n",
        "\n",
        "label_encoder = LabelEncoder()  # Создаем экземпляр класса LabelEncoder для преобразования категориальных меток в числовые значения\n",
        "\n",
        "# Кодируем столбец 'protocol' в числовые значения\n",
        "data['protocol'] = label_encoder.fit_transform(data['protocol'])  # Применяем кодирование к столбцу 'protocol' и сохраняем результат обратно в этот столбец\n"
      ],
      "metadata": {
        "id": "A29sYayNF-O5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "data['label'] = label_encoder.fit_transform(data['label'])"
      ],
      "metadata": {
        "id": "s206x7YjGIkX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаляем столбцы 'src_ip' и 'dst_ip' из датафрейма\n",
        "data.drop(['src_ip', 'dst_ip'], axis=1, inplace=True)  # Указываем axis=1 для удаления столбцов и inplace=True для изменения датафрейма на месте\n",
        "\n",
        "# Проверяем, что столбцы удалены, и выводим оставшиеся столбцы\n",
        "print(\"Оставшиеся столбцы:\\n\", data.columns)  # Выводим названия оставшихся столбцов в датафрейме\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBVBUMt2GJtm",
        "outputId": "66ace77b-4ec9-4c97-89e1-59ed1738aabd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оставшиеся столбцы:\n",
            " Index(['packet_rate', 'inter_arrival_time', 'packet_size', 'duration',\n",
            "       'src_port', 'dst_port', 'num_packets', 'num_bytes', 'protocol',\n",
            "       'label'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jIhUa-5WGTcP",
        "outputId": "fceb12ca-bd90-4e5e-a744-53f5d9e8d711"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   packet_rate  inter_arrival_time  packet_size  duration  src_port  dst_port  \\\n",
              "0    32.052620            0.622677   419.336437  4.460177      8801      9250   \n",
              "1    52.933578            0.492452   846.565643  4.435679      3708     51281   \n",
              "2    96.720151            0.185046   502.168275  4.431496     15306      6832   \n",
              "3    80.637373            0.137000   462.529046  4.675813     48304      9779   \n",
              "4    29.855090            0.601742   785.058163  5.295717     32704     65071   \n",
              "\n",
              "   num_packets    num_bytes  protocol  label  \n",
              "0    73.206250  7068.070150         0      0  \n",
              "1    38.226238  3848.110143         1      1  \n",
              "2    32.990155  7600.730151         1      0  \n",
              "3    71.610137  9700.654230         0      0  \n",
              "4    43.491605  4619.087460         1      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5551b31a-b31b-405b-b3d5-2753b4b89fd4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>packet_rate</th>\n",
              "      <th>inter_arrival_time</th>\n",
              "      <th>packet_size</th>\n",
              "      <th>duration</th>\n",
              "      <th>src_port</th>\n",
              "      <th>dst_port</th>\n",
              "      <th>num_packets</th>\n",
              "      <th>num_bytes</th>\n",
              "      <th>protocol</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32.052620</td>\n",
              "      <td>0.622677</td>\n",
              "      <td>419.336437</td>\n",
              "      <td>4.460177</td>\n",
              "      <td>8801</td>\n",
              "      <td>9250</td>\n",
              "      <td>73.206250</td>\n",
              "      <td>7068.070150</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>52.933578</td>\n",
              "      <td>0.492452</td>\n",
              "      <td>846.565643</td>\n",
              "      <td>4.435679</td>\n",
              "      <td>3708</td>\n",
              "      <td>51281</td>\n",
              "      <td>38.226238</td>\n",
              "      <td>3848.110143</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>96.720151</td>\n",
              "      <td>0.185046</td>\n",
              "      <td>502.168275</td>\n",
              "      <td>4.431496</td>\n",
              "      <td>15306</td>\n",
              "      <td>6832</td>\n",
              "      <td>32.990155</td>\n",
              "      <td>7600.730151</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80.637373</td>\n",
              "      <td>0.137000</td>\n",
              "      <td>462.529046</td>\n",
              "      <td>4.675813</td>\n",
              "      <td>48304</td>\n",
              "      <td>9779</td>\n",
              "      <td>71.610137</td>\n",
              "      <td>9700.654230</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>29.855090</td>\n",
              "      <td>0.601742</td>\n",
              "      <td>785.058163</td>\n",
              "      <td>5.295717</td>\n",
              "      <td>32704</td>\n",
              "      <td>65071</td>\n",
              "      <td>43.491605</td>\n",
              "      <td>4619.087460</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5551b31a-b31b-405b-b3d5-2753b4b89fd4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5551b31a-b31b-405b-b3d5-2753b4b89fd4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5551b31a-b31b-405b-b3d5-2753b4b89fd4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13d55d92-75ea-46bc-97a9-0727c64bace3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13d55d92-75ea-46bc-97a9-0727c64bace3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13d55d92-75ea-46bc-97a9-0727c64bace3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1999,\n  \"fields\": [\n    {\n      \"column\": \"packet_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27.333560457498532,\n        \"min\": 6.765443390496717,\n        \"max\": 160.52275989545686,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          96.36625110097928,\n          60.20327287368049,\n          60.18047321455949\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inter_arrival_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18098553805107634,\n        \"min\": 0.0767889765173756,\n        \"max\": 1.0879589253790858,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          0.2035972783891874,\n          0.3314954553955721,\n          0.6376752328897206\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"packet_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 269.8837026181031,\n        \"min\": 303.22572917849163,\n        \"max\": 1327.7915796893217,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          545.647104498695,\n          623.986402253252,\n          949.6794734775676\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0101168168588617,\n        \"min\": 1.6701232169570654,\n        \"max\": 8.353725325206408,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          4.59655465700998,\n          5.043990221016313,\n          3.20101133906338\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"src_port\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18704,\n        \"min\": 1049,\n        \"max\": 65532,\n        \"num_unique_values\": 1969,\n        \"samples\": [\n          9253,\n          59658,\n          42014\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dst_port\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18728,\n        \"min\": 1065,\n        \"max\": 65497,\n        \"num_unique_values\": 1965,\n        \"samples\": [\n          30354,\n          12746,\n          37267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_packets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.061267688345957,\n        \"min\": 17.707249476179612,\n        \"max\": 132.7880919017134,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          80.60790361903932,\n          46.8795991399649,\n          39.09672288340946\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_bytes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1389.7644875178148,\n        \"min\": 1018.1091266821776,\n        \"max\": 11172.015786662228,\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          4099.066057725138,\n          8313.530660815048,\n          5981.13568574663\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protocol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализуем числовые признаки с помощью MinMaxScaler\n",
        "scaler = MinMaxScaler()  # Создаем экземпляр MinMaxScaler для нормализации данных\n",
        "data[['packet_rate', 'inter_arrival_time', 'packet_size', 'duration', 'num_packets', 'num_bytes']] = scaler.fit_transform(\n",
        "    data[['packet_rate', 'inter_arrival_time', 'packet_size', 'duration', 'num_packets', 'num_bytes']]\n",
        ")  # Применяем нормализацию к указанным числовым признакам и сохраняем результат обратно в датафрейм\n",
        "\n",
        "# Разделяем данные на признаки (X) и метки (y)\n",
        "X = data.drop('label', axis=1)  # Убираем столбец 'label' из датафрейма для получения признаков\n",
        "y = data['label'].apply(lambda x: 1 if x == 'attack' else 0)  # Преобразуем метки в бинарный формат: 1 для 'attack', 0 для остальных\n",
        "\n",
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Делим данные на 80% для обучения и 20% для тестирования\n"
      ],
      "metadata": {
        "id": "77lrIRtWGlrN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Импортируем библиотеку pandas для работы с данными в формате таблиц\n",
        "import numpy as np  # Импортируем библиотеку NumPy для работы с массивами и математическими операциями\n",
        "import random  # Импортируем модуль random для генерации случайных чисел\n",
        "import gym  # Импортируем библиотеку gym для создания и работы со средами обучения с подкреплением\n",
        "import torch  # Импортируем библиотеку PyTorch для работы с нейронными сетями и тензорами\n",
        "import torch.nn as nn  # Импортируем модуль nn из PyTorch для создания нейронных сетей\n",
        "import torch.optim as optim  # Импортируем модуль optim для работы с оптимизаторами\n",
        "from tqdm import trange  # Импортируем trange из библиотеки tqdm для отображения прогресс-бара\n",
        "from gym import spaces  # Импортируем пространство действий и наблюдений из gym\n",
        "from sklearn.model_selection import train_test_split  # Импортируем функцию для разделения данных на обучающую и тестовую выборки\n",
        "from sklearn.preprocessing import StandardScaler  # Импортируем стандартный скейлер для нормализации\n"
      ],
      "metadata": {
        "id": "_PRzh0pAylr-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание среды для обучения с подкреплением (RL)\n",
        "class TrafficEnv(gym.Env):\n",
        "    def __init__(self, X, y):\n",
        "        super(TrafficEnv, self).__init__()  # Инициализация базового класса gym.Env\n",
        "        self.X = X  # Матрица признаков (входные данные)\n",
        "        self.y = y  # Вектор меток (0 или 1, целевая переменная)\n",
        "        self.current_index = 0  # Индекс текущего состояния\n",
        "        # Определяем пространство наблюдений (признаки)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(X.shape[1],), dtype=np.float32)\n",
        "        # Определяем пространство действий (доступные действия)\n",
        "        self.action_space = spaces.Discrete(2)  # 0 = пропустить, 1 = заблокировать\n",
        "\n",
        "    # Сброс среды к начальному состоянию\n",
        "    def reset(self):\n",
        "        self.current_index = 0  # Сбрасываем индекс текущего состояния\n",
        "        return self.X[self.current_index]  # Возвращаем начальное состояние\n",
        "\n",
        "    def step(self, action):\n",
        "        true_label = self.y[self.current_index]  # Получаем истинную метку для текущего состояния\n",
        "\n",
        "        # Награда: +1 за правильное действие, -1 за неправильное\n",
        "        if action == true_label:\n",
        "            reward = 1  # Правильное действие\n",
        "        else:\n",
        "            reward = -1  # Неправильное действие\n",
        "\n",
        "        self.current_index += 1  # Переходим к следующему состоянию\n",
        "        done = self.current_index >= len(self.X)  # Проверяем, достигли ли конца данных\n",
        "\n",
        "        if not done:\n",
        "            next_state = self.X[self.current_index]  # Получаем следующее состояние\n",
        "        else:\n",
        "            next_state = np.zeros_like(self.X[0])  # Пустое состояние в конце\n",
        "\n",
        "        return next_state, reward, done, {}  # Возвращаем следующее состояние, награду, флаг завершения и дополнительную информацию\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        pass  # Метод для визуализации среды (пока не реализован)\n"
      ],
      "metadata": {
        "id": "Am6RQQsdyy_n"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение нейросети (DQN)\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DQN, self).__init__()  # Инициализация базового класса nn.Module\n",
        "        self.model = nn.Sequential(  # Создаем последовательную модель\n",
        "            nn.Linear(input_dim, 128),  # Полносвязный слой с 128 нейронами\n",
        "            nn.ReLU(),  # Функция активации ReLU\n",
        "            nn.Linear(128, 64),  # Второй полносвязный слой с 64 нейронами\n",
        "            nn.ReLU(),  # Функция активации ReLU\n",
        "            nn.Linear(64, output_dim)  # Выходной слой (2 нейрона — Q-значения для действий)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)  # Прямое распространение через модель\n",
        "\n",
        "# Обучение DQN-агента\n",
        "# Выводим параметры\n",
        "state_dim = X_train.shape[1]  # Размерность состояния (количество признаков)\n",
        "action_dim = 2  # Количество действий (0 = пропустить, 1 = заблокировать)\n",
        "gamma = 0.99  # Коэффициент дисконтирования для будущих наград\n",
        "epsilon = 1.0  # Начальное значение ε для ε-greedy стратегии\n",
        "epsilon_min = 0.01  # Минимальное значение ε\n",
        "epsilon_decay = 0.995  # Скорость уменьшения ε\n",
        "lr = 0.001  # Скорость обучения (learning rate)\n",
        "batch_size = 64  # Размер батча для обучения\n",
        "replay_memory = deque(maxlen=10000)  # Буфер воспроизведения (replay memory) с максимальной длиной 10000\n",
        "\n",
        "# Инициализация\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Определяем устройство (GPU или CPU)\n",
        "policy_net = DQN(state_dim, action_dim).to(device)  # Создаем экземпляр DQN и отправляем на устройство\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=lr)  # Инициализируем оптимизатор Adam\n",
        "loss_fn = nn.MSELoss()  # Функция потерь (среднеквадратичная ошибка)\n",
        "\n",
        "# Функция действия (ε-greedy)\n",
        "def select_action(state, epsilon):\n",
        "    # Выбор действия (ε-greedy):\n",
        "    # С вероятностью ε — случайное действие\n",
        "    # Иначе — действие с максимальным Q-значением\n",
        "\n",
        "    if np.random.rand() < epsilon:  # Случайный выбор действия с вероятностью ε\n",
        "        return random.randint(0, action_dim - 1)  # Возвращаем случайное действие\n",
        "    state = torch.FloatTensor(state).unsqueeze(0).to(device)  # Преобразуем состояние в тензор и отправляем на устройство\n",
        "    with torch.no_grad():  # Отключаем градиенты для вычисления Q-значений\n",
        "        q_values = policy_net(state)  # Получаем Q-значения для текущего состояния\n",
        "    return torch.argmax(q_values).item()  # Возвращаем действие с максимальным Q-значением\n"
      ],
      "metadata": {
        "id": "Ap52tpB2y6U1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем экземпляр среды для обучения с подкреплением, передавая матрицу признаков и вектор меток\n",
        "env = TrafficEnv(X_train, y_train.values)  # Инициализация среды TrafficEnv с обучающими данными\n",
        "\n",
        "num_episodes = 100  # Устанавливаем количество эпизодов для обучения агента\n",
        "epsilon = 1.0  # Начальное значение ε для ε-greedy стратегии (максимальная вероятность случайного выбора действия)\n"
      ],
      "metadata": {
        "id": "Cl1tPiPUzAeV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 15000  # Максимальное количество шагов в одном эпизоде\n",
        "\n",
        "# Цикл по количеству эпизодов обучения\n",
        "for episode in trange(num_episodes, desc=\"Обучение агента\"):\n",
        "    state = env.reset()  # Сбрасываем среду и получаем начальное состояние\n",
        "    total_reward = 0  # Общая награда за эпизод\n",
        "    done = False  # Флаг завершения эпизода\n",
        "    step_count = 0  # Счетчик шагов\n",
        "\n",
        "    # Цикл, выполняющийся, пока эпизод не завершен и не достигнуто максимальное количество шагов\n",
        "    while not done and step_count < max_steps:\n",
        "        action = select_action(state, epsilon)  # Выбираем действие с помощью ε-greedy стратегии\n",
        "        next_state, reward, done, _ = env.step(action)  # Выполняем действие и получаем следующее состояние, награду и флаг завершения\n",
        "        total_reward += reward  # Обновляем общую награду\n",
        "        step_count += 1  # Увеличиваем счетчик шагов\n",
        "\n",
        "        # Сохраняем опыт в буфер воспроизведения\n",
        "        replay_memory.append((state, action, reward, next_state, done))\n",
        "        state = next_state  # Переходим к следующему состоянию\n",
        "\n",
        "        # Обучение модели из буфера воспроизведения, если достаточно данных\n",
        "        if len(replay_memory) >= batch_size:\n",
        "            batch = random.sample(replay_memory, batch_size)  # Случайная выборка из буфера\n",
        "            states, actions, rewards, next_states, dones = zip(*batch)  # Распаковываем выборку\n",
        "\n",
        "            # Преобразуем данные в массивы NumPy\n",
        "            states = np.array(states)\n",
        "            next_states = np.array(next_states)\n",
        "            actions = np.array(actions)\n",
        "            rewards = np.array(rewards)\n",
        "            dones = np.array(dones)\n",
        "\n",
        "            # Преобразуем данные в тензоры PyTorch и отправляем на устройство\n",
        "            states = torch.FloatTensor(states).to(device)\n",
        "            actions = torch.LongTensor(actions).unsqueeze(1).to(device)\n",
        "            rewards = torch.FloatTensor(rewards).unsqueeze(1).to(device)\n",
        "            next_states = torch.FloatTensor(next_states).to(device)\n",
        "            dones = torch.BoolTensor(dones).unsqueeze(1).to(device)\n",
        "\n",
        "            # Вычисляем Q-значения и обновляем модель\n",
        "            q_values = policy_net(states).gather(1, actions)  # Получаем Q-значения для выбранных действий\n",
        "            next_q_values = policy_net(next_states).max(1)[0].unsqueeze(1)  # Получаем максимальные Q-значения для следующих состояний\n",
        "            expected_q = rewards + gamma * next_q_values * (~dones)  # Вычисляем ожидаемые Q-значения\n",
        "\n",
        "            loss = loss_fn(q_values, expected_q.detach())  # Вычисляем функцию потерь\n",
        "            optimizer.zero_grad()  # Обнуляем градиенты\n",
        "            loss.backward()  # Обратное распространение ошибки\n",
        "            optimizer.step()  # Обновляем параметры модели\n",
        "\n",
        "    # Обновляем значение epsilon для ε-greedy стратегии\n",
        "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "    # Выводим информацию о текущем эпизоде\n",
        "    print(f\"Эпизод {episode + 1}: Общая награда = {total_reward}, шагов: {step_count}, ε = {epsilon:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzZWpwaEzGQK",
        "outputId": "3990c380-e1c6-4ccb-b976-f452b5d7c79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обучение агента:   1%|          | 1/100 [00:40<1:07:07, 40.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 1: Общая награда = -24, шагов: 15000, ε = 0.995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:   2%|▏         | 2/100 [01:21<1:06:14, 40.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 2: Общая награда = -202, шагов: 15000, ε = 0.990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:   3%|▎         | 3/100 [02:00<1:04:44, 40.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 3: Общая награда = 356, шагов: 15000, ε = 0.985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:   4%|▍         | 4/100 [02:40<1:03:52, 39.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 4: Общая награда = 170, шагов: 15000, ε = 0.980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:   5%|▌         | 5/100 [03:20<1:03:23, 40.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 5: Общая награда = 176, шагов: 15000, ε = 0.975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:   6%|▌         | 6/100 [04:01<1:03:19, 40.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 6: Общая награда = 536, шагов: 15000, ε = 0.970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:   7%|▋         | 7/100 [04:44<1:03:47, 41.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 7: Общая награда = 464, шагов: 15000, ε = 0.966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:   8%|▊         | 8/100 [05:26<1:03:26, 41.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 8: Общая награда = 520, шагов: 15000, ε = 0.961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:   9%|▉         | 9/100 [06:08<1:03:01, 41.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 9: Общая награда = 694, шагов: 15000, ε = 0.956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  10%|█         | 10/100 [06:52<1:03:35, 42.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 10: Общая награда = 654, шагов: 15000, ε = 0.951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  11%|█         | 11/100 [07:37<1:03:57, 43.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 11: Общая награда = 760, шагов: 15000, ε = 0.946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  12%|█▏        | 12/100 [08:27<1:06:20, 45.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 12: Общая награда = 934, шагов: 15000, ε = 0.942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  13%|█▎        | 13/100 [09:12<1:05:44, 45.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 13: Общая награда = 650, шагов: 15000, ε = 0.937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  14%|█▍        | 14/100 [09:58<1:05:09, 45.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 14: Общая награда = 952, шагов: 15000, ε = 0.932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  15%|█▌        | 15/100 [10:45<1:04:53, 45.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 15: Общая награда = 978, шагов: 15000, ε = 0.928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  16%|█▌        | 16/100 [11:32<1:04:38, 46.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 16: Общая награда = 1068, шагов: 15000, ε = 0.923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  17%|█▋        | 17/100 [12:18<1:04:01, 46.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 17: Общая награда = 1242, шагов: 15000, ε = 0.918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  18%|█▊        | 18/100 [13:06<1:03:46, 46.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 18: Общая награда = 1348, шагов: 15000, ε = 0.914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  19%|█▉        | 19/100 [13:54<1:03:25, 46.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 19: Общая награда = 1284, шагов: 15000, ε = 0.909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  20%|██        | 20/100 [14:43<1:03:26, 47.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 20: Общая награда = 1306, шагов: 15000, ε = 0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  21%|██        | 21/100 [15:32<1:03:17, 48.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 21: Общая награда = 1470, шагов: 15000, ε = 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  22%|██▏       | 22/100 [16:19<1:02:14, 47.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 22: Общая награда = 1418, шагов: 15000, ε = 0.896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  23%|██▎       | 23/100 [17:07<1:01:32, 47.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 23: Общая награда = 1528, шагов: 15000, ε = 0.891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  24%|██▍       | 24/100 [17:55<1:00:29, 47.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 24: Общая награда = 1516, шагов: 15000, ε = 0.887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  25%|██▌       | 25/100 [18:42<59:41, 47.75s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 25: Общая награда = 1708, шагов: 15000, ε = 0.882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  26%|██▌       | 26/100 [19:30<58:40, 47.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 26: Общая награда = 1650, шагов: 15000, ε = 0.878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  27%|██▋       | 27/100 [20:19<58:39, 48.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 27: Общая награда = 2088, шагов: 15000, ε = 0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  28%|██▊       | 28/100 [21:08<58:03, 48.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 28: Общая награда = 2046, шагов: 15000, ε = 0.869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  29%|██▉       | 29/100 [21:57<57:21, 48.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 29: Общая награда = 1784, шагов: 15000, ε = 0.865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  30%|███       | 30/100 [22:45<56:35, 48.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 30: Общая награда = 1954, шагов: 15000, ε = 0.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  31%|███       | 31/100 [23:33<55:22, 48.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 31: Общая награда = 1982, шагов: 15000, ε = 0.856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  32%|███▏      | 32/100 [24:21<54:37, 48.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 32: Общая награда = 2088, шагов: 15000, ε = 0.852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  33%|███▎      | 33/100 [25:10<54:13, 48.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 33: Общая награда = 2188, шагов: 15000, ε = 0.848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  34%|███▍      | 34/100 [25:59<53:20, 48.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 34: Общая награда = 2212, шагов: 15000, ε = 0.843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  35%|███▌      | 35/100 [26:47<52:36, 48.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 35: Общая награда = 2202, шагов: 15000, ε = 0.839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  36%|███▌      | 36/100 [27:37<52:10, 48.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 36: Общая награда = 2530, шагов: 15000, ε = 0.835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  37%|███▋      | 37/100 [28:26<51:13, 48.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 37: Общая награда = 2530, шагов: 15000, ε = 0.831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  38%|███▊      | 38/100 [29:17<51:19, 49.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 38: Общая награда = 2436, шагов: 15000, ε = 0.827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  39%|███▉      | 39/100 [30:08<50:41, 49.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 39: Общая награда = 2616, шагов: 15000, ε = 0.822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  40%|████      | 40/100 [30:57<49:51, 49.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 40: Общая награда = 2442, шагов: 15000, ε = 0.818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  41%|████      | 41/100 [31:47<48:51, 49.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 41: Общая награда = 2726, шагов: 15000, ε = 0.814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  42%|████▏     | 42/100 [32:37<48:19, 50.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 42: Общая награда = 2854, шагов: 15000, ε = 0.810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  43%|████▎     | 43/100 [33:26<47:09, 49.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 43: Общая награда = 2972, шагов: 15000, ε = 0.806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  44%|████▍     | 44/100 [34:15<46:04, 49.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 44: Общая награда = 2970, шагов: 15000, ε = 0.802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  45%|████▌     | 45/100 [35:06<45:40, 49.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 45: Общая награда = 2940, шагов: 15000, ε = 0.798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  46%|████▌     | 46/100 [35:56<45:00, 50.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 46: Общая награда = 3210, шагов: 15000, ε = 0.794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  47%|████▋     | 47/100 [36:48<44:32, 50.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 47: Общая награда = 2916, шагов: 15000, ε = 0.790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  48%|████▊     | 48/100 [37:37<43:28, 50.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 48: Общая награда = 3058, шагов: 15000, ε = 0.786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  49%|████▉     | 49/100 [38:27<42:33, 50.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 49: Общая награда = 2876, шагов: 15000, ε = 0.782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  50%|█████     | 50/100 [39:17<41:35, 49.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 50: Общая награда = 3238, шагов: 15000, ε = 0.778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  51%|█████     | 51/100 [40:06<40:31, 49.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 51: Общая награда = 3266, шагов: 15000, ε = 0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  52%|█████▏    | 52/100 [40:54<39:25, 49.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 52: Общая награда = 3472, шагов: 15000, ε = 0.771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  53%|█████▎    | 53/100 [41:40<37:50, 48.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 53: Общая награда = 3510, шагов: 15000, ε = 0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  54%|█████▍    | 54/100 [42:27<36:47, 47.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 54: Общая награда = 3532, шагов: 15000, ε = 0.763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  55%|█████▌    | 55/100 [43:15<35:48, 47.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 55: Общая награда = 3634, шагов: 15000, ε = 0.759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  56%|█████▌    | 56/100 [44:02<34:50, 47.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 56: Общая награда = 3704, шагов: 15000, ε = 0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  57%|█████▋    | 57/100 [44:49<34:02, 47.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 57: Общая награда = 3674, шагов: 15000, ε = 0.751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  58%|█████▊    | 58/100 [45:38<33:34, 47.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 58: Общая награда = 3648, шагов: 15000, ε = 0.748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  59%|█████▉    | 59/100 [46:26<32:51, 48.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 59: Общая награда = 3560, шагов: 15000, ε = 0.744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  60%|██████    | 60/100 [47:15<32:09, 48.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 60: Общая награда = 3830, шагов: 15000, ε = 0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  61%|██████    | 61/100 [48:03<31:19, 48.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 61: Общая награда = 3798, шагов: 15000, ε = 0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  62%|██████▏   | 62/100 [48:52<30:36, 48.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 62: Общая награда = 4034, шагов: 15000, ε = 0.733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  63%|██████▎   | 63/100 [49:41<29:53, 48.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 63: Общая награда = 3880, шагов: 15000, ε = 0.729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  64%|██████▍   | 64/100 [50:30<29:13, 48.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 64: Общая награда = 3876, шагов: 15000, ε = 0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  65%|██████▌   | 65/100 [51:19<28:31, 48.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 65: Общая награда = 4112, шагов: 15000, ε = 0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  66%|██████▌   | 66/100 [52:08<27:40, 48.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 66: Общая награда = 4146, шагов: 15000, ε = 0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  67%|██████▋   | 67/100 [52:56<26:47, 48.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 67: Общая награда = 4102, шагов: 15000, ε = 0.715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  68%|██████▊   | 68/100 [53:45<25:58, 48.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 68: Общая награда = 4482, шагов: 15000, ε = 0.711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  69%|██████▉   | 69/100 [54:33<25:04, 48.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 69: Общая награда = 4288, шагов: 15000, ε = 0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  70%|███████   | 70/100 [55:21<24:10, 48.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 70: Общая награда = 4140, шагов: 15000, ε = 0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  71%|███████   | 71/100 [56:09<23:18, 48.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 71: Общая награда = 4538, шагов: 15000, ε = 0.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  72%|███████▏  | 72/100 [56:57<22:30, 48.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 72: Общая награда = 4434, шагов: 15000, ε = 0.697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  73%|███████▎  | 73/100 [57:46<21:43, 48.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 73: Общая награда = 4682, шагов: 15000, ε = 0.694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  74%|███████▍  | 74/100 [58:34<20:53, 48.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 74: Общая награда = 4630, шагов: 15000, ε = 0.690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  75%|███████▌  | 75/100 [59:21<19:57, 47.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 75: Общая награда = 4548, шагов: 15000, ε = 0.687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  76%|███████▌  | 76/100 [1:00:09<19:13, 48.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 76: Общая награда = 4916, шагов: 15000, ε = 0.683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  77%|███████▋  | 77/100 [1:00:57<18:21, 47.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 77: Общая награда = 4694, шагов: 15000, ε = 0.680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  78%|███████▊  | 78/100 [1:01:44<17:31, 47.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 78: Общая награда = 4698, шагов: 15000, ε = 0.676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  79%|███████▉  | 79/100 [1:02:32<16:41, 47.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 79: Общая награда = 4878, шагов: 15000, ε = 0.673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  80%|████████  | 80/100 [1:03:20<15:58, 47.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 80: Общая награда = 5178, шагов: 15000, ε = 0.670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  81%|████████  | 81/100 [1:04:09<15:14, 48.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 81: Общая награда = 4932, шагов: 15000, ε = 0.666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  82%|████████▏ | 82/100 [1:04:58<14:30, 48.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 82: Общая награда = 4860, шагов: 15000, ε = 0.663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  83%|████████▎ | 83/100 [1:05:46<13:43, 48.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 83: Общая награда = 5034, шагов: 15000, ε = 0.660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  84%|████████▍ | 84/100 [1:06:35<12:56, 48.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 84: Общая награда = 5200, шагов: 15000, ε = 0.656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  85%|████████▌ | 85/100 [1:07:23<12:03, 48.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 85: Общая награда = 5056, шагов: 15000, ε = 0.653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  86%|████████▌ | 86/100 [1:08:12<11:21, 48.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 86: Общая награда = 5266, шагов: 15000, ε = 0.650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  87%|████████▋ | 87/100 [1:09:02<10:35, 48.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 87: Общая награда = 5178, шагов: 15000, ε = 0.647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  88%|████████▊ | 88/100 [1:09:50<09:45, 48.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 88: Общая награда = 5232, шагов: 15000, ε = 0.643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  89%|████████▉ | 89/100 [1:10:39<08:55, 48.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 89: Общая награда = 5176, шагов: 15000, ε = 0.640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  90%|█████████ | 90/100 [1:11:27<08:04, 48.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 90: Общая награда = 5378, шагов: 15000, ε = 0.637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  91%|█████████ | 91/100 [1:12:15<07:14, 48.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 91: Общая награда = 5460, шагов: 15000, ε = 0.634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  92%|█████████▏| 92/100 [1:13:02<06:24, 48.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 92: Общая награда = 5432, шагов: 15000, ε = 0.631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  93%|█████████▎| 93/100 [1:13:50<05:37, 48.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 93: Общая награда = 5612, шагов: 15000, ε = 0.627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  94%|█████████▍| 94/100 [1:14:39<04:50, 48.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 94: Общая награда = 5620, шагов: 15000, ε = 0.624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  95%|█████████▌| 95/100 [1:15:28<04:02, 48.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 95: Общая награда = 5600, шагов: 15000, ε = 0.621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  96%|█████████▌| 96/100 [1:16:16<03:13, 48.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 96: Общая награда = 5410, шагов: 15000, ε = 0.618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  97%|█████████▋| 97/100 [1:17:03<02:24, 48.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 97: Общая награда = 5812, шагов: 15000, ε = 0.615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  98%|█████████▊| 98/100 [1:17:52<01:36, 48.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 98: Общая награда = 5764, шагов: 15000, ε = 0.612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rОбучение агента:  99%|█████████▉| 99/100 [1:18:42<00:48, 48.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 99: Общая награда = 5902, шагов: 15000, ε = 0.609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обучение агента: 100%|██████████| 100/100 [1:19:32<00:00, 47.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпизод 100: Общая награда = 5888, шагов: 15000, ε = 0.606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Переводим X_test в numpy\n",
        "X_test_np = np.array(X_test)  # Преобразуем тестовые данные в массив NumPy\n",
        "y_test_np = np.array(y_test)  # Преобразуем вектор меток тестовых данных в массив NumPy\n",
        "\n",
        "# Получим предсказания от агента\n",
        "predictions = []  # Список для хранения предсказанных действий\n",
        "\n",
        "with torch.no_grad():  # Отключаем вычисление градиентов для экономии памяти\n",
        "    for state in X_test_np:  # Проходим по каждому состоянию в тестовом наборе\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)  # Преобразуем состояние в тензор и отправляем на устройство\n",
        "        q_values = policy_net(state_tensor)  # Получаем Q-значения от нейросети\n",
        "        action = torch.argmax(q_values).item()  # Выбираем действие с максимальным Q-значением\n",
        "        predictions.append(action)  # Добавляем предсказанное действие в список\n",
        "\n",
        "# Метрики\n",
        "print(\"Classification Report:\")  # Выводим отчет о классификации\n",
        "print(classification_report(y_test_np, predictions, target_names=[\"Benign\", \"Attack\"]))  # Печатаем отчет с метриками для классов\n",
        "\n",
        "print(\"Confusion Matrix:\")  # Выводим матрицу ошибок\n",
        "print(confusion_matrix(y_test_np, predictions))  # Печатаем матрицу ошибок для сравнения истинных и предсказанных меток\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOrplT0uFqUR",
        "outputId": "5fcd364a-170f-40fb-85b6-ddfffbcf6987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.82      0.49      0.62      4020\n",
            "      Attack       0.08      0.30      0.13       614\n",
            "\n",
            "    accuracy                           0.47      4634\n",
            "   macro avg       0.45      0.40      0.37      4634\n",
            "weighted avg       0.72      0.47      0.55      4634\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1980 2040]\n",
            " [ 431  183]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка модели\n",
        "def evaluate_model(model, X, y):\n",
        "    model.eval()  # Убедимся, что модель в режиме оценки (выключаем режим обучения)\n",
        "    # Получаем предсказания для каждого состояния в X\n",
        "    predictions = [np.argmax(model(torch.tensor(np.array([x]), dtype=torch.float32)).detach().numpy()) for x in X]\n",
        "    # Выводим отчет о классификации, сравнивая истинные метки и предсказанные\n",
        "    print(classification_report(y, predictions))\n",
        "\n",
        "# Вызываем функцию оценки модели, передавая нейросеть и тестовые данные\n",
        "evaluate_model(policy_net, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__ipMVAjFuy7",
        "outputId": "f44432d7-3886-455e-93fe-7d3fe4b2d28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.49      0.62      4020\n",
            "           1       0.08      0.30      0.13       614\n",
            "\n",
            "    accuracy                           0.47      4634\n",
            "   macro avg       0.45      0.40      0.37      4634\n",
            "weighted avg       0.72      0.47      0.55      4634\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier  # Импортируем класс RandomForestClassifier из библиотеки scikit-learn\n",
        "from sklearn.svm import SVC  # Импортируем класс SVC (Support Vector Classifier) из библиотеки scikit-learn\n",
        "\n",
        "# Сравнение с классическими методами\n",
        "rf = RandomForestClassifier()  # Создаем экземпляр классификатора Random Forest\n",
        "rf.fit(X_train, y_train)  # Обучаем модель на обучающих данных\n",
        "y_pred_rf = rf.predict(X_test)  # Получаем предсказания для тестовых данных\n",
        "print(\"Random Forest:\")  # Выводим заголовок для результатов Random Forest\n",
        "print(classification_report(y_test, y_pred_rf))  # Печатаем отчет о классификации для Random Forest\n",
        "\n",
        "svm = SVC()  # Создаем экземпляр классификатора SVM\n",
        "svm.fit(X_train, y_train)  # Обучаем модель на обучающих данных\n",
        "y_pred_svm = svm.predict(X_test)  # Получаем предсказания для тестовых данных\n",
        "print(\"SVM:\")  # Выводим заголовок для результатов SVM\n",
        "print(classification_report(y_test, y_pred_svm))  # Печатаем отчет о классификации для SVM\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgCkg9t1F0FN",
        "outputId": "407006d0-3981-4fee-d1b1-2deb96eda28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      4020\n",
            "           1       1.00      1.00      1.00       614\n",
            "\n",
            "    accuracy                           1.00      4634\n",
            "   macro avg       1.00      1.00      1.00      4634\n",
            "weighted avg       1.00      1.00      1.00      4634\n",
            "\n",
            "SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      4020\n",
            "           1       0.99      0.95      0.97       614\n",
            "\n",
            "    accuracy                           0.99      4634\n",
            "   macro avg       0.99      0.97      0.98      4634\n",
            "weighted avg       0.99      0.99      0.99      4634\n",
            "\n"
          ]
        }
      ]
    }
  ]
}